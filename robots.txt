# See http://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# To ban all spiders from the entire site uncomment the next two lines:
# User-agent: *
# Disallow: /

#allowing all spiders from entire site to crawl

 User-agent: *
 Disallow: 
 
 Sitemap: https://nilanshbansal.github.io/sitemap.xml
 


